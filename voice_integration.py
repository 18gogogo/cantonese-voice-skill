#!/usr/bin/env python3
"""
èªéŸ³å°è©±é›†æˆæ¨¡çµ„
æ•´åˆ CosyVoice (TTS) å’Œ Whisper (ASR)

ä½¿ç”¨æ–¹æ³•:
    from voice_integration import VoiceConversation

    conversation = VoiceConversation()

    # è­˜åˆ¥ç”¨æˆ¶èªéŸ³
    result = conversation.transcribe('/path/to/user_voice.ogg')

    # ç­‰å¾…ç”¨æˆ¶ç¢ºèª
    if result['success']:
        print(f"è­˜åˆ¥çµæœ: {result['text']}")

        # ç™¼é€èªéŸ³å›æ‡‰
        conversation.respond_speech("æ”¶åˆ°ï¼æˆ‘æ­£åœ¨è™•ç†æ‚¨çš„è«‹æ±‚ã€‚")
"""

import os
import sys

# æ·»åŠ è·¯å¾‘
COSYVOICE_DIR = '/home/ubuntu/CosyVoice'
sys.path.insert(0, f'{COSYVOICE_DIR}/third_party/Matcha-TTS')
sys.path.insert(0, COSYVOICE_DIR)

from voice_asr import transcribe_audio
from voice_tts import synthesize_speech
from voice_output_manager import VoiceOutputManager


class VoiceConversation:
    """
    èªéŸ³å°è©±é¡
    æ•´åˆ ASR å’Œ TTS åŠŸèƒ½
    """

    def __init__(
        self,
        model_dir: str = None,
        whisper_model: str = 'turbo',
        default_language: str = 'yue',
        output_dir: str = '/home/ubuntu/æ¡Œé¢/ok',
        voice_output_manager: VoiceOutputManager = None
    ):
        """
        åˆå§‹åŒ–èªéŸ³å°è©±

        Args:
            model_dir: CosyVoice æ¨¡å‹ç›®éŒ„
            whisper_model: Whisper æ¨¡å‹åç¨±
            default_language: é»˜èªèªè¨€ (yue - å»£æ±è©±)
            output_dir: è¼¸å‡ºç›®éŒ„
            voice_output_manager: èªéŸ³è¼¸å‡ºç®¡ç†å™¨
        """
        self.model_dir = model_dir or f'{COSYVOICE_DIR}/pretrained_models/Fun-CosyVoice3-0.5B'
        self.whisper_model = whisper_model
        self.default_language = default_language
        self.output_dir = output_dir
        self.voice_output = voice_output_manager or VoiceOutputManager()

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)

    def transcribe(
        self,
        audio_file: str,
        language: str = None
    ) -> dict:
        """
        è­˜åˆ¥èªéŸ³è¼¸å…¥

        Args:
            audio_file: éŸ³é »æ–‡ä»¶è·¯å¾‘
            language: èªè¨€ä»£ç¢¼ (é»˜èª: default_language)

        Returns:
            dict: è­˜åˆ¥çµæœ
        """
        if language is None:
            language = self.default_language

        result = transcribe_audio(
            audio_file=audio_file,
            language=language,
            model_name=self.whisper_model
        )

        # è™•ç†èªéŸ³è¼¸å‡ºæ§åˆ¶å‘½ä»¤
        if result['success']:
            parse_result = self.voice_output.parse_command(result['text'])
            result['text'] = parse_result['text']
            result['voice_enabled'] = parse_result['voice_enabled']
            result['control_action'] = parse_result['action']

        return result

    def synthesize(
        self,
        text: str,
        output_file: str = None,
        speed: float = 1.0,
        force: bool = False,
        timeout: float = 50  # è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
    ) -> dict:
        """
        åˆæˆèªéŸ³è¼¸å‡º

        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            output_file: è¼¸å‡ºæ–‡ä»¶è·¯å¾‘ (é»˜èª: è‡ªå‹•ç”Ÿæˆ)
            speed: èªéŸ³é€Ÿåº¦
            force: å¼·åˆ¶åˆæˆï¼ˆå¿½ç•¥èªéŸ³è¼¸å‡ºç‹€æ…‹ï¼‰
            timeout: è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰

        Returns:
            dict: åˆæˆçµæœ
        """
        # æª¢æŸ¥èªéŸ³è¼¸å‡ºæ˜¯å¦å•Ÿç”¨
        if not force and not self.voice_output.is_enabled():
            return {
                'success': False,
                'output_file': None,
                'duration': 0,
                'error': 'voice_output_disabled',
                'message': 'èªéŸ³è¼¸å‡ºå·²é—œé–‰'
            }

        # ç”Ÿæˆè¼¸å‡ºæ–‡ä»¶è·¯å¾‘
        if output_file is None:
            import time
            timestamp = int(time.time())
            output_file = f'{self.output_dir}/voice_response_{timestamp}.wav'

        return synthesize_speech(
            text=text,
            output_file=output_file,
            model_dir=self.model_dir,
            speed=speed,
            timeout=timeout
        )

    def respond_speech(
        self,
        text: str,
        display_text: bool = True,
        speed: float = 1.0,
        force: bool = False,
        timeout: float = 50  # è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
    ) -> dict:
        """
        ç™¼é€èªéŸ³å›æ‡‰ (å¸¶é¡¯ç¤ºæ–‡å­—)

        Args:
            text: å›æ‡‰æ–‡æœ¬
            display_text: æ˜¯å¦é¡¯ç¤ºæ–‡å­—
            speed: èªéŸ³é€Ÿåº¦
            force: å¼·åˆ¶åˆæˆï¼ˆå¿½ç•¥èªéŸ³è¼¸å‡ºç‹€æ…‹ï¼‰

        Returns:
            dict: åˆæˆçµæœ
                - success: æ˜¯å¦æˆåŠŸ
                - output_file: éŸ³é »æ–‡ä»¶è·¯å¾‘ï¼ˆå¦‚æœèªéŸ³é–‹å•Ÿä¸”ä¸æ˜¯ç´”æ§åˆ¶æŒ‡ä»¤ï¼‰
                - duration: éŸ³é »é•·åº¦
                - action: æ§åˆ¶æŒ‡ä»¤é¡å‹ï¼ˆ'enable', 'disable', æˆ– Noneï¼‰
                - message: ä¿¡æ¯
                - voice_enabled: èªéŸ³è¼¸å‡ºæ˜¯å¦å•Ÿç”¨
        """
        # æª¢æŸ¥ä¸¦è™•ç†èªéŸ³è¼¸å‡ºæ§åˆ¶å‘½ä»¤
        parse_result = self.voice_output.parse_command(text)
        processed_text = parse_result['text']
        action = parse_result['action']
        voice_enabled = parse_result['voice_enabled']

        # æ§‹å»ºçµæœ
        result = {
            'success': True,
            'output_file': None,
            'duration': 0,
            'action': action,
            'message': None,
            'voice_enabled': voice_enabled
        }

        # å¦‚æœä¸æ˜¯ç´”æ§åˆ¶æŒ‡ä»¤ï¼Œç”ŸæˆèªéŸ³
        if processed_text.strip():
            # è¨ˆç®—é è¨ˆåˆæˆæ™‚é–“ï¼ˆæ¯å­—ç´„ 1.5 ç§’ï¼‰
            estimated_seconds = len(processed_text) * 1.5
            max_safe_seconds = 50  # æœ€å¤§å®‰å…¨æ™‚é–“ï¼ˆç§’ï¼‰
            max_safe_chars = int(max_safe_seconds / 1.5)  # æœ€å¤š 33 å­—

            original_text = processed_text
            text_truncated = False

            # æª¢æŸ¥æ˜¯å¦éœ€è¦æˆªæ–·
            if len(processed_text) > max_safe_chars:
                processed_text = processed_text[:max_safe_chars] + "..."
                text_truncated = True
                print(f"âš ï¸ æ–‡æœ¬éé•·ï¼ˆ{len(original_text)} å­—ï¼Œé è¨ˆ {estimated_seconds:.1f} ç§’ > 50 ç§’ï¼‰")
                print(f"âœ‚ï¸  è‡ªå‹•æˆªæ–·ç‚º {max_safe_chars} å­—ä»¥ä¿è­‰åœ¨ 50 ç§’å…§å®Œæˆ")
            else:
                # æ­£å¸¸æ–‡æœ¬ï¼Œé¡¯ç¤ºé€²åº¦æç¤º
                print(f"â³ èªéŸ³åˆæˆä¸­...ï¼ˆé è¨ˆ {estimated_seconds:.1f} ç§’ï¼‰")

            synthesis_result = self.synthesize(processed_text, speed=speed, force=force, timeout=timeout)

            # æª¢æŸ¥æ˜¯å¦è¶…æ™‚
            if synthesis_result.get('timed_out'):
                print("âš ï¸ èªéŸ³åˆæˆè¶…æ™‚ï¼åƒ…è¿”å›æ–‡å­—å›æ‡‰")
                result['timed_out'] = True
                result['message'] = 'synthesis_timeout'

            result['output_file'] = synthesis_result.get('output_file')
            result['duration'] = synthesis_result.get('duration', 0)
            result['success'] = synthesis_result['success']
            result['original_text'] = original_text  # ä¿å­˜åŸå§‹æ–‡æœ¬
            result['text_truncated'] = text_truncated  # è¨˜éŒ„æ˜¯å¦æˆªæ–·
        else:
            # ç´”æ§åˆ¶æŒ‡ä»¤ï¼Œè¨­ç½®æ¶ˆæ¯
            if action == 'enable':
                result['message'] = 'voice_output_enabled'
            elif action == 'disable':
                result['message'] = 'voice_output_disabled'

        # é¡¯ç¤ºæ–‡å­—
        if display_text:
            print("=" * 60)
            if processed_text.strip():
                if result.get('timed_out'):
                    # è¶…æ™‚æƒ…æ³
                    print("âš ï¸ èªéŸ³åˆæˆè¶…æ™‚")
                    print("=" * 60)
                    print(f"ğŸ“ æ–‡å­—: {original_text}")
                    print(f"â±ï¸  èªªæ˜: åˆæˆæ™‚é–“è¶…é {timeout} ç§’ï¼Œåƒ…è¿”å›æ–‡å­—")
                elif result['success'] and result.get('output_file'):
                    # æˆåŠŸç”ŸæˆèªéŸ³
                    if result.get('text_truncated'):
                        print("âœ‚ï¸  æ–‡æœ¬å·²è‡ªå‹•æˆªæ–·")
                        print("=" * 60)
                        print(f"ğŸ“ åŸå§‹æ–‡æœ¬: {original_text}")
                        print(f"ğŸ“ åˆæˆæ–‡æœ¬: {processed_text}")
                        print(f"ğŸ“ éŸ³é »: {result['output_file']}")
                        print(f"ğŸ“ é•·åº¦: {result['duration']:.2f} ç§’")
                        print(f"ğŸ’¡ èªªæ˜: æ–‡æœ¬éé•·å·²æˆªæ–·ä»¥ä¿è­‰åœ¨ 50 ç§’å…§å®Œæˆ")
                    else:
                        print("ğŸ”Š èªéŸ³å›æ‡‰")
                        print("=" * 60)
                        print(f"ğŸ“ æ–‡å­—: {processed_text}")
                        print(f"ğŸ“ éŸ³é »: {result['output_file']}")
                        print(f"ğŸ“ é•·åº¦: {result['duration']:.2f} ç§’")
                else:
                    # èªéŸ³è¼¸å‡ºé—œé–‰æˆ–å¤±æ•—
                    print("ğŸ“ æ–‡å­—å›æ‡‰")
                    print("=" * 60)
                    original_full = result.get('original_text', original_text)
                    print(f"ğŸ“ æ–‡å­—: {original_full}")
                    if result.get('message'):
                        print(f"â„¹ï¸  ç‹€æ…‹: {result['message']}")
            elif action:
                # æ§åˆ¶æŒ‡ä»¤
                status_text = "é–‹å•Ÿ" if action == 'enable' else "é—œé–‰"
                print("ğŸ›ï¸ æ§åˆ¶æŒ‡ä»¤å·²åŸ·è¡Œ")
                print("=" * 60)
                print(f"ğŸ“Š èªéŸ³è¼¸å‡ºç‹€æ…‹: {status_text}")
                print(f"ğŸ“ å»ºè­°å›æ‡‰: èªéŸ³è¼¸å‡ºå·²{status_text}")
            print("=" * 60)

        return result

    def conversation_flow(
        self,
        user_audio: str,
        ai_response: str
    ) -> dict:
        """
        å®Œæ•´å°è©±æµç¨‹ (æ‰‹å‹•ç¢ºèªæ¨¡å¼)

        Args:
            user_audio: ç”¨æˆ¶èªéŸ³æ–‡ä»¶
            ai_response: AI å›æ‡‰æ–‡æœ¬

        Returns:
            dict: å®Œæ•´å°è©±çµæœ
        """
        result = {
            'transcription': None,
            'confirmation': False,
            'response': None,
            'success': False
        }

        # 1. è­˜åˆ¥ç”¨æˆ¶èªéŸ³
        print("=" * 60)
        print("ğŸ¤ èªéŸ³è­˜åˆ¥ä¸­...")
        print("=" * 60)
        transcription_result = self.transcribe(user_audio)

        if not transcription_result['success']:
            print(f"âŒ è­˜åˆ¥å¤±æ•—: {transcription_result['error']}")
            return result

        # é¡¯ç¤ºè­˜åˆ¥çµæœ
        print("\nè­˜åˆ¥çµæœ:")
        print(f"  {transcription_result['text']}")
        print(f"  (æ—¶é•·: {transcription_result['duration']:.2f} ç§’)")
        print()

        # 2. ç­‰å¾…ç”¨æˆ¶ç¢ºèª
        print("=" * 60)
        print("â“ è«‹ç¢ºèªè­˜åˆ¥çµæœ")
        print("=" * 60)
        print("[1] âœ“ ç¢ºèª")
        print("[2] ä¿®æ”¹æ–‡å­—")
        print("[3] å–æ¶ˆ")
        print()

        # æ³¨æ„ï¼šé€™è£¡éœ€è¦å¯¦éš›çš„ç”¨æˆ¶è¼¸å…¥é‚è¼¯
        # åœ¨ Telegram Bot ä¸­æœƒé€šéæŒ‰éˆ•å¯¦ç¾
        result['transcription'] = transcription_result
        result['confirmation'] = True  # é»˜èªç¢ºèª

        # 3. ç™¼é€èªéŸ³å›æ‡‰
        if result['confirmation']:
            response_result = self.respond_speech(ai_response)
            result['response'] = response_result
            result['success'] = response_result['success']
        else:
            print("âš ï¸ ç”¨æˆ¶å–æ¶ˆå°è©±")

        return result

    def enable_voice_output(self) -> bool:
        """
        é–‹å•ŸèªéŸ³è¼¸å‡º

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return self.voice_output.enable()

    def disable_voice_output(self) -> bool:
        """
        é—œé–‰èªéŸ³è¼¸å‡º

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        return self.voice_output.disable()

    def toggle_voice_output(self) -> bool:
        """
        åˆ‡æ›èªéŸ³è¼¸å‡ºç‹€æ…‹

        Returns:
            bool: åˆ‡æ›å¾Œçš„ç‹€æ…‹ï¼ˆTrue = é–‹å•Ÿï¼‰
        """
        return self.voice_output.toggle()

    def is_voice_output_enabled(self) -> bool:
        """
        æª¢æŸ¥èªéŸ³è¼¸å‡ºæ˜¯å¦å•Ÿç”¨

        Returns:
            bool: æ˜¯å¦å•Ÿç”¨
        """
        return self.voice_output.is_enabled()

    def get_voice_output_status(self) -> str:
        """
        ç²å–èªéŸ³è¼¸å‡ºç‹€æ…‹ä¿¡æ¯

        Returns:
            str: ç‹€æ…‹ä¿¡æ¯
        """
        return self.voice_output.get_status_info()


def test_voice_conversation():
    """
    æ¸¬è©¦èªéŸ³å°è©±æµç¨‹
    """
    # å‰µå»ºå°è©±å¯¦ä¾‹
    conversation = VoiceConversation()

    print("=" * 60)
    print("ğŸ“Š èªéŸ³å°è©±æ¸¬è©¦")
    print("=" * 60)
    print()

    # æ¸¬è©¦æ–‡æœ¬è¼¸å…¥ (ä¸éœ€è¦å¯¦éš›éŸ³é »)
    test_text = "ä½ å¥½ï¼Œä»Šæ—¥å¤©æ°£å¾ˆå¥½ï¼Œæˆ‘æƒ³å»è¡Œå±±ã€‚"
    print(f"æ¸¬å ´æ™¯: ç”¨æˆ¶èªªã€Œ{test_text}ã€")
    print()

    # æ¨¡æ“¬ AI å›æ‡‰
    ai_response = "æ”¶åˆ°ï¼ä»Šæ—¥å¤©æ°£å¾ˆå¥½ï¼Œå»è¡Œå±±æ˜¯ä¸€å€‹å¾ˆå¥½çš„ä¸»æ„ã€‚è¦å¸¶è¶³æ°´å’Œæ³¨æ„å®‰å…¨å“¦ï¼"
    print(f"AI å›æ‡‰: {ai_response}")
    print()

    # åˆæˆèªéŸ³
    result = conversation.respond_speech(ai_response)

    if result['success']:
        print("\nâœ… èªéŸ³å°è©±æ¸¬è©¦å®Œæˆï¼")
    else:
        print(f"\nâŒ æ¸¬è©¦å¤±æ•—: {result['error']}")


def main():
    """
    ä¸»ç¨‹åº
    """
    import argparse

    parser = argparse.ArgumentParser(description='èªéŸ³å°è©±é›†æˆæ¸¬è©¦')
    parser.add_argument('--mode', type=str, default='test',
                       choices=['test', 'asr', 'tts', 'conversation'],
                       help='æ¸¬è©¦æ¨¡å¼')
    parser.add_argument('--audio', type=str,
                       help='éŸ³é »æ–‡ä»¶ (ç”¨æ–¼ asr æˆ– conversation æ¨¡å¼)')
    parser.add_argument('--text', type=str,
                       help='æ–‡æœ¬ (ç”¨æ–¼ tts æ¨¡å¼)')
    parser.add_argument('--output', type=str,
                       help='è¼¸å‡ºæ–‡ä»¶ (ç”¨æ–¼ tts æ¨¡å¼)')

    args = parser.parse_args()

    conversation = VoiceConversation()

    if args.mode == 'test':
        test_voice_conversation()

    elif args.mode == 'asr':
        if not args.audio:
            print("éŒ¯èª¤ï¼šasr æ¨¡å¼éœ€è¦ --audio åƒæ•¸")
            return

        result = conversation.transcribe(args.audio)
        if result['success']:
            print(f"è­˜åˆ¥çµæœ: {result['text']}")
        else:
            print(f"è­˜åˆ¥å¤±æ•—: {result['error']}")

    elif args.mode == 'tts':
        if not args.text:
            print("éŒ¯èª¤ï¼štts æ¨¡å¼éœ€è¦ --text åƒæ•¸")
            return

        result = conversation.synthesize(
            text=args.text,
            output_file=args.output
        )
        if result['success']:
            print(f"åˆæˆæˆåŠŸ: {result['output_file']} ({result['duration']:.2f}s)")
        else:
            print(f"åˆæˆå¤±æ•—: {result['error']}")

    elif args.mode == 'conversation':
        if not args.audio:
            print("éŒ¯èª¤ï¼šconversation æ¨¡å¼éœ€è¦ --audio åƒæ•¸")
            return

        # æ¨¡æ“¬å°è©± (ä¸éœ€è¦ AI å¯¦éš›å›æ‡‰)
        result = conversation.conversation_flow(
            user_audio=args.audio,
            ai_response="æ”¶åˆ°ï¼æˆ‘æ­£åœ¨è™•ç†æ‚¨çš„è«‹æ±‚ã€‚"
        )

        print(f"\nå°è©±çµæœ: {'æˆåŠŸ' if result['success'] else 'å¤±æ•—'}")


if __name__ == '__main__':
    main()
